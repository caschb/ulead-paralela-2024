#+TITLE: Leyes de Amdahl y Gustafson-Barsis y Medición de Rendimiento en Programas de OpenMP
#+AUTHOR: Christian Asch

* Introducción al rendimiento paralelo y la escalabilidad 
** Speedup
El speedup es una comparación relativa entre dos casos de ejecución.

** Escalabilidad
La escalabilidad se refiere a la forma en que los programas responden
a distintos niveles de recursos.

** Eficiencia
Qué tan bien se usan los recursos para obtener el Speedup

** Partes secuenciales y paralelas de los programas

** Overhead paralelo

* Ley de Amdahl
** Introducción a la ley de Amdahl
*** Fórmula y derivación
$$S_{n} = \frac{t_{1}}{t_{n}}$$

$$t_{1} = t_{s} + t_{p} = 1$$

$$t_{n} = t_{s} + \frac{t_{p}}{n} = 1 - t_{p} + \frac{t_{p}}{n}$$

$$S_{n} = \frac{1}{(1-t_{p})+\frac{t_{p}}{n}}$$

$$\lim_{n\to\infty} S_{n} = \frac{1}{1-t_{p}}$$

** Aplicabilidad de la ley de Amdahl
** Ejemplo y graficación
En este código graficamos la cantidad de procesadores contra el speedup obtenido para varios programas con distintos porcentajes de paralelismo.
#+begin_src python :tangle no :python ./.venv/bin/python :results file link :exports both
  import matplotlib.pyplot as plt
  import numpy as np
  def amdahl_speedup(p, n):
      return 1.0 / (1 - p + p/n)

  name = "./amdahl.png"
  procs = np.arange(1, 100)
  parallel_portions = np.arange(0, 1, 0.2)
  plt.xlabel("Cantidad de procesadores")
  plt.ylabel("Speedup")
  for par in parallel_portions:
      result = amdahl_speedup(par, procs)
      plt.plot(procs, result, label=f"{par:.1}")
  plt.legend()
  plt.savefig(name)
  return name
#+end_src

#+RESULTS:
[[file:./amdahl.png]]

* Ley de Gustafson
** Introducción a la ley de Gustafson
*** Fórmula y derivación

$$S_{n} = \frac{t_{1}}{t_{n}}$$
$$t_{n} = t_{s} + t_{p} = 1$$
$$t_{1} = t_{s} + n \cdot t_{p}$$

$$S_{n} = 1 - t_{p} + n \cdot t_{p}$$
$$S_{n} = 1 + t_{p} \cdot (n - 1 )$$

** Aplicabilidad de la ley de Gustafson 
** Ejemplo y graficación

#+begin_src python :tangle no :python ./.venv/bin/python :results file link :exports both
  import matplotlib.pyplot as plt
  import numpy as np
  def gustafson_speedup(p, n):
      return 1 + p * (n - 1)

  name = "./gustafson.png"
  procs = np.arange(1, 100)
  parallel_portions = np.arange(0, 1, 0.2)
  plt.xlabel("Cantidad de procesadores")
  plt.ylabel("Speedup")
  for par in parallel_portions:
      result = gustafson_speedup(par, procs)
      plt.plot(procs, result, label=f"{par:.1}")
  plt.legend()
  plt.savefig(name)
  return name
#+end_src

#+RESULTS:
[[file:./gustafson.png]]

* Descanso (15 minutos)
* Cómo medir el tiempo de programas de OpenMP?
** Jerarquía de memoria
- Concepto
- L1d, L1i, L2, L3 Cache
- Cache lines

Para realizar los siguientes ejemplos nos vamos a concentrar en la operación SAXPY, "Single precision A X plus Y". Esta operación es la siguiente:

$$\boldsymbol{z}=a\:\boldsymbol{x} + \boldsymbol{y}$$

** Makefile y programa

Las primeras líneas del Makefile nos indican cuál es el compilador que utilizaremos, así como banderas necesarias para realizar la compilación. En este caso utilizamos ~-fopenmp~ para que el programa pueda encontrar las bibliotecas necesarias.

#+begin_src makefile :tangle Makefile
CC=gcc-14
FLAGS=-fopenmp -O3
#+end_src
Luego definimos los comandos de compilación. En este contexto, ~sm~ significa "shared memory".
#+begin_src makefile :tangle Makefile
all: saxpy_serial saxpy_sm

saxpy_serial: saxpy_serial.c
	${CC} ${FLAGS} -o $@ $?

saxpy_sm: saxpy_sm.c
	${CC} ${FLAGS} -o $@ $?
#+end_src

** Medición del speedup y la eficiencia de un programa de OpenMP
#+begin_src c :tangle saxpy_serial.c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <omp.h>
void saxpy(float a, float * x, float * y, int elements)
{
  for(int i = 0; i < elements; ++i)
  {
    y[i] = a * x[i] + y[i];
  }
}
int main(int argc, char ** argv)
{
  double start, end;
  int total_elements = atoi(argv[1]);
  float a, *x, *y;
  a = 10.f;
  start = omp_get_wtime();
  x = malloc(sizeof(float) * total_elements);
  y = malloc(sizeof(float) * total_elements);

  for(int i = 0; i < total_elements; ++i)
  {
    x[i] = 1.f;
    y[i] = 2.3f;
  }
  end = omp_get_wtime() - start;
  printf("Init time: %f\n", end);
  start = omp_get_wtime();
  saxpy(a, x, y, total_elements);
  end = omp_get_wtime() - start;
  printf("Execution time: %f\n", end);
  free(x);
  free(y);
  return 0;
}

#+end_src
#+begin_src c :tangle saxpy_sm.c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <omp.h>
void saxpy(float a, float * x, float * y, const int elements, const int chunk_size)
{
#pragma omp parallel for schedule(static, chunk_size) default(none) shared(a, x, y, chunk_size, elements)
  for(int i = 0; i < elements; ++i)
  {
    y[i] = a * x[i] + y[i];
  }
}
int main(int argc, char ** argv)
{
  double start, end;
  int total_elements = atoi(argv[1]);
  int chunk_size = atoi(argv[2]);
  float a, *x, *y;
  a = 10.f;
  start = omp_get_wtime();
  x = malloc(sizeof(float) * total_elements);
  y = malloc(sizeof(float) * total_elements);

#pragma omp parallel for schedule(static, chunk_size) default(none) shared(total_elements, x, y, chunk_size)
  for(int i = 0; i < total_elements; ++i)
  {
    x[i] = 1.f;
    y[i] = 2.3f;
  }
  end = omp_get_wtime() - start;
  printf("Init time: %f\n", end);
  start = omp_get_wtime();
  saxpy(a, x, y, total_elements, chunk_size);
  end = omp_get_wtime() - start;
  printf("Execution time: %f\n", end);
  free(x);
  free(y);
  return 0;
}

#+end_src

** Posibles problemas de rendimiento
- Overhead
- False sharing
** Strong scaling
** Weak scaling 
** Práctica con multiplicación de matrices
#+begin_src makefile :tangle practice/Makefile
CC=gcc-14
FLAGS=-fopenmp -O3
all: matmul_serial

matmul_serial: matmul_serial.c
	${CC} ${FLAGS} -o $@ $?

#+end_src
#+begin_src c :tangle practice/matmul_serial.c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

typedef struct {
  double * data;
  int height;
  int width;
} Matrix;

inline double get_element(const Matrix *mat, int i, int j);
inline void set_element(Matrix *mat, int i, int j, double val);

double get_element(const Matrix *mat, int i, int j)
{
  int index = mat->width * i + j;
  return mat->data[index];
}

void set_element(Matrix *mat, int i, int j, double val)
{
  int index = mat->width * i + j;
  mat->data[index] = val;
}

void free_matrix(Matrix *mat)
{
  free(mat->data);
  mat->data = NULL;

  free(mat);
  mat = NULL;
}

Matrix * alloc_matrix(int height, int width)
{
  int total_elements = height * width;
  Matrix *mat = malloc(sizeof(Matrix));
  mat->height = height;
  mat->width = width;
  mat->data = malloc(sizeof(double) * total_elements);
  return mat;
}

Matrix * create_n_matrix(int height, int width, int n)
{
  int total_elements = height * width;
  Matrix *mat = alloc_matrix(height, width);
  memset(mat->data, n, total_elements);
  return mat;
}

Matrix * create_rand_matrix(int height, int width)
{
  int total_elements = height * width;
  Matrix *mat = alloc_matrix(height, width);
  
  for(int i = 0; i < total_elements; ++i)
  {
    mat->data[i] = 1. + rand()/(RAND_MAX + 1.)/10;
  }

  return mat;
}

Matrix * matmul(const Matrix *matA, const Matrix *matB)
{
  Matrix * matC = create_n_matrix(matA->height, matB->width, 0);
  for(int i = 0; i < matA->height; ++i)
  {
    for(int j = 0; j < matB->width; ++j)
    {
      double value = .0;
      for(int k = 0; k < matA->width; ++k)
      {
        value += get_element(matA, i, k) * get_element(matB, k, j);
      }
      set_element(matC, i, j, value);
    }
  }
  return matC;
}

void print_matrix(const Matrix * mat)
{
  for(int i = 0; i < mat->height; ++i)
  {
    for(int j = 0; j < mat->width; ++j)
    {
      printf("%f ", get_element(mat, i, j));
    }
    printf("\n");
  }
}

int main()
{
  Matrix * matA = create_rand_matrix(3, 4);
  Matrix * matB = create_rand_matrix(4, 1);
  Matrix * matC = matmul(matA, matB);
  print_matrix(matC);
  free_matrix(matA);
  free_matrix(matB);
  free_matrix(matC);
  return 0;
}
#+end_src

* Resumen y preguntas (15 minutos)
